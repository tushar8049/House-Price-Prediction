{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Housing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushar8049/House-Price-Prediction/blob/master/Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_Q0-xT3Qf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn -y\n",
        "!pip install Cython\n",
        "!pip install git+https://github.com/scikit-learn/scikit-learn.git\n",
        "\n",
        "\n",
        "  \n",
        "\"\"\"\n",
        "['RandomForestRegressor', 'ExtraTreesRegressor', 'BaggingRegressor',\n",
        "'GradientBoostingRegressor', 'AdaBoostRegressor', \n",
        "'GaussianProcessRegressor', 'IsotonicRegression', 'ARDRegression', \n",
        "'HuberRegressor', 'LinearRegression', 'LogisticRegression', \n",
        "'LogisticRegressionCV', 'PassiveAggressiveRegressor', \n",
        "'RandomizedLogisticRegression', 'SGDRegressor', 'TheilSenRegressor', \n",
        "'RANSACRegressor', 'MultiOutputRegressor', 'KNeighborsRegressor', \n",
        "'RadiusNeighborsRegressor', 'MLPRegressor', 'DecisionTreeRegressor', \n",
        "'ExtraTreeRegressor', <class 'sklearn.svm.classes.SVR'>]\n",
        "\"\"\"  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo16M2yoFmXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDF9U2483Vc3",
        "colab_type": "code",
        "outputId": "35a3844e-1991-4abf-e9e1-f3057a09dd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#import Data\n",
        "training_data = pd.read_csv('https://raw.githubusercontent.com/tushar8049/House-Price-Prediction/master/train.csv')\n",
        "testing_data = pd.read_csv('https://raw.githubusercontent.com/tushar8049/House-Price-Prediction/master/test.csv')\n",
        "#names = [\"Id\",\"MSSubClass\",\"MSZoning\",\"LotFrontage\",\"LotArea\",\"Street\",\"Alley\",\"LotShape\",\"LandContour\",\"Utilities\",\"LotConfig\",\"LandSlope\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\"Exterior2nd\",\"MasVnrType\",\"MasVnrArea\",\"ExterQual\",\"ExterCond\",\"Foundation\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinSF1\",\"BsmtFinType2\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"Heating\",\"HeatingQC\",\"CentralAir\",\"Electrical\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"KitchenQual\",\"TotRmsAbvGrd\",\"Functional\",\"Fireplaces\",\"FireplaceQu\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageCars\",\"GarageArea\",\"GarageQual\",\"GarageCond\",\"PavedDrive\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"PoolQC\",\"Fence\",\"MiscFeature\",\"MiscVal\",\"MoSold\",\"YrSold\",\"SaleType\",\"SaleCondition\",\"SalePrice\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Remove the Header and the ID Column\n",
        "training_data = training_data.iloc[1:,1:]\n",
        "testing_id = testing_data.iloc[1:,0]\n",
        "testing_id = pd.DataFrame(testing_id)\n",
        "#thisis = testing_id\n",
        "testing_data = testing_data.iloc[:,1:]\n",
        "#print(thisis)\n",
        "\n",
        "print()\n",
        "\n",
        "testing_data = pd.DataFrame(testing_data)\n",
        "training_data = pd.DataFrame(training_data)\n",
        "print(training_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "ncols = len(training_data.columns)\n",
        "nrows = len(training_data.index)\n",
        "training = training_data.iloc[:, 0:(ncols - 1)].values.reshape(nrows, ncols - 1)\n",
        "y_train = training_data.iloc[:, (ncols - 1)].values.reshape(nrows, 1)\n",
        "print(\"Y_TRAIN: \",y_train.shape)\n",
        "print(training.shape)\n",
        "print(testing_data.shape)\n",
        "#training_data = training + testing_data\n",
        "\n",
        "\n",
        "\n",
        "training_data = training\n",
        "testing_data = pd.DataFrame(testing_data, columns = [\"MSSubClass\",\"MSZoning\",\"LotFrontage\",\"LotArea\",\"Street\",\"Alley\",\"LotShape\",\"LandContour\",\"Utilities\",\"LotConfig\",\"LandSlope\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\"Exterior2nd\",\"MasVnrType\",\"MasVnrArea\",\"ExterQual\",\"ExterCond\",\"Foundation\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinSF1\",\"BsmtFinType2\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"Heating\",\"HeatingQC\",\"CentralAir\",\"Electrical\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"KitchenQual\",\"TotRmsAbvGrd\",\"Functional\",\"Fireplaces\",\"FireplaceQu\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageCars\",\"GarageArea\",\"GarageQual\",\"GarageCond\",\"PavedDrive\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"PoolQC\",\"Fence\",\"MiscFeature\",\"MiscVal\",\"MoSold\",\"YrSold\",\"SaleType\",\"SaleCondition\"])\n",
        "training_data = pd.DataFrame(training_data)\n",
        "training = pd.DataFrame(training, columns = [\"MSSubClass\",\"MSZoning\",\"LotFrontage\",\"LotArea\",\"Street\",\"Alley\",\"LotShape\",\"LandContour\",\"Utilities\",\"LotConfig\",\"LandSlope\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\"Exterior2nd\",\"MasVnrType\",\"MasVnrArea\",\"ExterQual\",\"ExterCond\",\"Foundation\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinSF1\",\"BsmtFinType2\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"Heating\",\"HeatingQC\",\"CentralAir\",\"Electrical\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"KitchenQual\",\"TotRmsAbvGrd\",\"Functional\",\"Fireplaces\",\"FireplaceQu\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageCars\",\"GarageArea\",\"GarageQual\",\"GarageCond\",\"PavedDrive\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"PoolQC\",\"Fence\",\"MiscFeature\",\"MiscVal\",\"MoSold\",\"YrSold\",\"SaleType\",\"SaleCondition\"])\n",
        "\n",
        "\n",
        "#result = pd.concat([training,testing_data],axis = 0)\n",
        "result = training.append(testing_data)\n",
        "print(\"Result: \",result.shape)\n",
        "#print(result)\n",
        "print(\"Training_data\",training_data.shape)\n",
        "\n",
        "print(\"Testing_data\",testing_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "headers_for_category = [1,4,5,6,7,8,9,10,11,12,13,14,15,20,21,22,23,24,26,27,28,29,30,31,32,34,38,39,40,41,52,54,56,57,59,62,63,64,71,72,73,77,78]\n",
        "le = {}\n",
        "\n",
        "\"\"\"for i in headers_for_category:\n",
        "  #print(i)\n",
        "  le[i] = preprocessing.LabelEncoder()\n",
        "  a = pd.DataFrame(training_data.iloc[:,i])\n",
        "  a[pd.isnull(a)] = 'NaN'\n",
        "  #le[i].fit(training_data.iloc[:,i])\n",
        "  #training_data.iloc[:,i] = le[i].transform(training_data.iloc[:,i])\n",
        "  \n",
        "  le[i].fit(a)\n",
        "  training_data.iloc[:,i] = le[i].transform(a)\n",
        "  \n",
        "  \n",
        "  #For Testing Data\n",
        "  \n",
        "  a = pd.DataFrame(testing_data.iloc[:,i])\n",
        "  a[pd.isnull(a)] = 'NaN'\n",
        "  #le[i].fit(training_data.iloc[:,i])\n",
        "  #training_data.iloc[:,i] = le[i].transform(training_data.iloc[:,i])\n",
        "  \n",
        "  le[i].fit(a)\n",
        "  testing_data.iloc[:,i] = le[i].transform(a)\n",
        "  \n",
        "  \"\"\"\n",
        "\"\"\"\n",
        "si = Imputer(missing_values=np.nan, strategy='most_frequent')\n",
        "si.fit(training_data)\n",
        "training_data = si.transform(training_data)\n",
        "training_data = pd.DataFrame(training_data)\n",
        "\n",
        "testing_data = si.transform(testing_data)\n",
        "testing_data = pd.DataFrame(testing_data)\n",
        "\n",
        "#headers_for_numerical = [0,2,3,16,17,18,19,25,33,35,36,37,42,43,44,45,46,47,48,49,50,51,53,55,58,60,61,65,66,67,68,67,70,74,75,76,79]\n",
        "\"\"\"\n",
        "\"\"\"\"\n",
        "si = {}\n",
        "for i in headers_for_numerical:\n",
        "  si[i] = Imputer(missing_values=np.nan, strategy='most_frequent')\n",
        "  si[i].fit(training_data.iloc[:,i])\n",
        "  training_data.iloc[:,i] = si[i].transform(training_data.iloc[:,i])\n",
        "\"\"\"\"\"\"\"\n",
        "\n",
        "print(training_data.shape)\n",
        "print(testing_data.shape)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "headers_for_category = [1,4,5,6,7,8,9,10,11,12,13,14,15,20,21,22,23,24,26,27,28,29,30,31,32,34,38,39,40,41,52,54,56,57,59,62,63,64,71,72,73,77,78]\n",
        "le = {}\n",
        "\n",
        "for i in headers_for_category:\n",
        "  #print(i)\n",
        "  le[i] = preprocessing.LabelEncoder()\n",
        "  a = pd.DataFrame(result.iloc[:,i])\n",
        "  a[pd.isnull(a)] = 'NaN'\n",
        "  #le[i].fit(training_data.iloc[:,i])\n",
        "  #training_data.iloc[:,i] = le[i].transform(training_data.iloc[:,i])\n",
        "  \n",
        "  le[i].fit(a)\n",
        "  result.iloc[:,i] = le[i].transform(a)\n",
        "  \n",
        "\n",
        "si = Imputer(missing_values=np.nan, strategy='most_frequent')\n",
        "si.fit(result)\n",
        "result = si.transform(result)\n",
        "result = pd.DataFrame(result)\n",
        "\n",
        "#print(result)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(1459, 80)\n",
            "Y_TRAIN:  (1459, 1)\n",
            "(1459, 79)\n",
            "(1459, 79)\n",
            "Result:  (2918, 79)\n",
            "Training_data (1459, 79)\n",
            "Testing_data (1459, 79)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SKT91X4UWNA",
        "colab_type": "code",
        "outputId": "b5e6dc9b-d3b7-4d8e-b28b-8528cf743d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "\"\"\"ipca = IncrementalPCA(n_components=10, batch_size=20)\n",
        "ipca.fit(x_train)\n",
        "\n",
        "x_train = ipca.transform(x_train) \n",
        "print(x_train)\n",
        "print(x_train.shape)\n",
        "print(ipca.explained_variance_ratio_)\n",
        "\n",
        "ipca = IncrementalPCA(n_components=10, batch_size=20)\n",
        "ipca.fit(testing_data)\n",
        "testing_data = ipca.transform(testing_data) \n",
        "print(testing_data)\n",
        "print(testing_data.shape)\n",
        "print(ipca.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "testing_data = scaler.transform(testing_data)\n",
        "x_maindata = x_train\n",
        "y_maintarget = y_train\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "ipca = IncrementalPCA(n_components=10, batch_size=20)\n",
        "ipca.fit(result)\n",
        "\n",
        "result = ipca.transform(result) \n",
        "print(result)\n",
        "print(result.shape)\n",
        "print(ipca.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(result)\n",
        "result = scaler.transform(result)\n",
        "\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::: \\n\")\n",
        "print(result)\n",
        "\n",
        "#x_maindata = x_train\n",
        "#y_maintarget = y_train\n",
        "\n",
        "\n",
        "result = pd.DataFrame(result)\n",
        "ncols = len(result.columns)\n",
        "nrows = len(result.index)\n",
        "final_training_dataset = result.iloc[0:(int(nrows/2)), :].values.reshape((int(nrows/2)), ncols)\n",
        "final_testing_dataset = result.iloc[(int(nrows/2)):nrows, :].values.reshape((int(nrows/2)), ncols)\n",
        "final_training_target = y_train\n",
        "print(final_training_dataset.shape)\n",
        "print(final_testing_dataset.shape)\n",
        "print(final_training_target.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-5.63121943e+02  1.05779118e+02 -6.46207320e+02 ... -5.67818128e+01\n",
            "  -1.09282062e+02  2.01308883e+02]\n",
            " [ 1.08174760e+03 -8.44860239e-01  4.32713016e+02 ...  1.13474573e+02\n",
            "  -4.68816314e+00 -1.14262364e+02]\n",
            " [-6.23676836e+02 -1.42172308e+02  5.18713341e+02 ...  1.18954676e+02\n",
            "  -1.57126894e+02 -1.20504964e+02]\n",
            " ...\n",
            " [ 9.83326187e+03 -2.32721331e+02 -8.25625786e+02 ...  6.13765151e+01\n",
            "  -1.54854895e+02  3.43551889e+02]\n",
            " [ 2.55501688e+02 -4.94410935e+02 -5.89113828e+02 ... -3.13967416e+02\n",
            "   1.14086340e+02  6.34049970e+01]\n",
            " [-5.30506428e+02  3.01933696e+02  3.88651223e+02 ...  7.22250036e+01\n",
            "  -1.10543017e+02  5.25469793e+01]]\n",
            "(2918, 10)\n",
            "[9.75093705e-01 7.61898714e-03 5.40370120e-03 4.87291634e-03\n",
            " 4.24576793e-03 8.67630531e-04 5.31567566e-04 4.90671460e-04\n",
            " 3.56812282e-04 2.19959943e-04]\n",
            "\n",
            " :::::::::::::::::::::::::::::::: \n",
            "\n",
            "[[-7.13627426e-02  1.51650348e-01 -1.10006319e+00 ... -3.20758295e-01\n",
            "  -7.23888898e-01  1.69733281e+00]\n",
            " [ 1.37086606e-01 -1.21123481e-03  7.36623751e-01 ...  6.41013535e-01\n",
            "  -3.10545866e-02 -9.63401402e-01]\n",
            " [-7.90366813e-02 -2.03825485e-01  8.83025361e-01 ...  6.71970426e-01\n",
            "  -1.04081505e+00 -1.01603579e+00]\n",
            " ...\n",
            " [ 1.24613957e+00 -3.33641190e-01 -1.40549404e+00 ...  3.46713593e-01\n",
            "  -1.02576523e+00  2.89665257e+00]\n",
            " [ 3.23789570e-02 -7.08812778e-01 -1.00287077e+00 ... -1.77358996e+00\n",
            "   7.55712636e-01  5.34598276e-01]\n",
            " [-6.72294770e-02  4.32867574e-01  6.61615693e-01 ...  4.07996290e-01\n",
            "  -7.32241515e-01  4.43049063e-01]]\n",
            "(1459, 10)\n",
            "(1459, 10)\n",
            "(1459, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuj0PJVl7Adq",
        "colab_type": "code",
        "outputId": "ac8839e9-ea9f-4334-8163-7af9c438eb7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2054
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(final_training_dataset, final_training_target, test_size=.30)\n",
        "  reg = RandomForestRegressor(max_depth=50, random_state=1, n_estimators=100, max_features='auto')\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "\n",
        "reg = RandomForestRegressor(max_depth=50, random_state=1, n_estimators=100, max_features='auto')\n",
        "  \n",
        "reg.fit(final_training_dataset, final_training_target)\n",
        "\n",
        "predicted_value = reg.predict(final_testing_dataset)\n",
        "print(predicted_value)\n",
        "predicted_value = np.insert(predicted_value,0,0)\n",
        "predicted_value = pd.DataFrame(predicted_value,columns = [\"SalePrice\"])\n",
        "\n",
        "final_predicted_values = pd.concat([testing_id, predicted_value], axis=1)\n",
        "final_predicted_values = final_predicted_values.iloc[1:,:]\n",
        "print(final_predicted_values)\n",
        "result.to_csv(\"test_results_final.csv\", encoding='utf-8', index=False)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = RandomForestRegressor(max_depth=100, random_state=1, n_estimators=50, max_features='auto', verbose=1)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[120284.   348599.51 176584.1  ... 177571.88 116942.46 231694.47]\n",
            "          Id  SalePrice\n",
            "1     1462.0  120284.00\n",
            "2     1463.0  348599.51\n",
            "3     1464.0  176584.10\n",
            "4     1465.0  185109.30\n",
            "5     1466.0  165854.13\n",
            "6     1467.0  178044.69\n",
            "7     1468.0  170062.73\n",
            "8     1469.0  161524.45\n",
            "9     1470.0  179876.73\n",
            "10    1471.0  143875.50\n",
            "11    1472.0  216271.16\n",
            "12    1473.0  106501.00\n",
            "13    1474.0  138428.38\n",
            "14    1475.0  161190.55\n",
            "15    1476.0  113542.06\n",
            "16    1477.0  293974.79\n",
            "17    1478.0  242197.88\n",
            "18    1479.0  259889.53\n",
            "19    1480.0  276661.78\n",
            "20    1481.0  490855.96\n",
            "21    1482.0  323325.03\n",
            "22    1483.0  186626.89\n",
            "23    1484.0  165413.54\n",
            "24    1485.0  161480.90\n",
            "25    1486.0  148181.08\n",
            "26    1487.0  191486.75\n",
            "27    1488.0  307129.62\n",
            "28    1489.0  240115.61\n",
            "29    1490.0  183490.80\n",
            "30    1491.0  222062.07\n",
            "...      ...        ...\n",
            "1430  2891.0   92221.61\n",
            "1431  2892.0  162966.00\n",
            "1432  2893.0   86177.00\n",
            "1433  2894.0  102167.49\n",
            "1434  2895.0   82775.50\n",
            "1435  2896.0  277015.52\n",
            "1436  2897.0  270389.99\n",
            "1437  2898.0  198695.59\n",
            "1438  2899.0  184498.13\n",
            "1439  2900.0  206638.10\n",
            "1440  2901.0  155129.50\n",
            "1441  2902.0  253192.50\n",
            "1442  2903.0  192200.90\n",
            "1443  2904.0  305691.79\n",
            "1444  2905.0  328328.26\n",
            "1445  2906.0  187828.07\n",
            "1446  2907.0  210339.65\n",
            "1447  2908.0  112454.32\n",
            "1448  2909.0  120337.00\n",
            "1449  2910.0  240475.40\n",
            "1450  2911.0   86880.00\n",
            "1451  2912.0   97851.33\n",
            "1452  2913.0  160601.00\n",
            "1453  2914.0  126119.03\n",
            "1454  2915.0   81092.00\n",
            "1455  2916.0   81327.00\n",
            "1456  2917.0   93768.16\n",
            "1457  2918.0  177571.88\n",
            "1458  2919.0  116942.46\n",
            "1459     NaN  231694.47\n",
            "\n",
            "[1459 rows x 2 columns]\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n",
            "explained_variance_score:  [0.7317624923551147, 0.6679717845615234, 0.7163482177898091, 0.7278070248889656, 0.6759085872499617, 0.6819467011968756, 0.6656943561995454, 0.7176315588253755, 0.6988655598088013, 0.805886952913312]\n",
            "mean_squared_error:  [1504349398.6197495, 1909530487.9116244, 1944404173.726803, 1584197548.3469827, 1873598934.8132358, 1681036761.1376057, 1941091503.3988533, 1895425076.8474197, 2106782245.3717074, 1143059440.1841097]\n",
            "mean_squared_log_error:  [0.0366452987413645, 0.04176626183510277, 0.04830044187134135, 0.0459311629618121, 0.04468227870991522, 0.04397587208133479, 0.049401116038271256, 0.039024616893942383, 0.0454544881753994, 0.033386498462164654]\n",
            "r2_score:  [0.7314526960577453, 0.6665878816245401, 0.7160957762760563, 0.7239065876582338, 0.6730530556332054, 0.6791943344627385, 0.6656674321487202, 0.7175625060386033, 0.698554331056318, 0.8045184880085758]\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n",
            "explained_variance_score:  0.7089823235789284\n",
            "mean_squared_error:  1758347557.035809\n",
            "mean_squared_log_error:  0.04285680357706484\n",
            "r2_score:  0.7076593088964737\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-61f42daf4733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_maindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_maintarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_maindata' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCkp4nx4Gamw",
        "colab_type": "code",
        "outputId": "3603f782-f516-4d1c-c1d8-606a3e541285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4117
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "  reg = RandomForestRegressor(max_depth=50, random_state=1, n_estimators=100, max_features='auto')\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "predicted_value = reg.predict(testing_data)\n",
        "print(predicted_value)\n",
        "predicted_value = np.insert(predicted_value,0,0)\n",
        "predicted_value = pd.DataFrame(predicted_value)\n",
        "\n",
        "result = pd.concat([testing_id, predicted_value], axis=1)\n",
        "result = result.iloc[1:,:]\n",
        "print(result)\n",
        "result.to_csv(\"test_results1.csv\", encoding='utf-8', index=False)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = RandomForestRegressor(max_depth=100, random_state=1, n_estimators=50, max_features='auto', verbose=1)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n",
            "[154189.88 430033.45 167151.87 ... 173672.95 165927.09 207923.02]\n",
            "        Id          0\n",
            "1     1461  154189.88\n",
            "2     1462  430033.45\n",
            "3     1463  167151.87\n",
            "4     1464  181719.48\n",
            "5     1465  191798.71\n",
            "6     1466  127675.83\n",
            "7     1467  225890.24\n",
            "8     1468  130282.96\n",
            "9     1469  188314.20\n",
            "10    1470  177969.48\n",
            "11    1471  255108.67\n",
            "12    1472  123398.32\n",
            "13    1473  134481.55\n",
            "14    1474  195846.85\n",
            "15    1475  139592.30\n",
            "16    1476  232790.71\n",
            "17    1477  164456.54\n",
            "18    1478  215680.17\n",
            "19    1479  215026.78\n",
            "20    1480  471588.52\n",
            "21    1481  247967.01\n",
            "22    1482  201438.58\n",
            "23    1483  132461.22\n",
            "24    1484  185445.10\n",
            "25    1485  119164.46\n",
            "26    1486  135187.74\n",
            "27    1487  246440.79\n",
            "28    1488  213634.48\n",
            "29    1489  169078.84\n",
            "30    1490  279615.51\n",
            "...    ...        ...\n",
            "1430  2890   98751.29\n",
            "1431  2891  142730.19\n",
            "1432  2892  108581.78\n",
            "1433  2893  107864.08\n",
            "1434  2894   97149.50\n",
            "1435  2895  294833.60\n",
            "1436  2896  330532.56\n",
            "1437  2897  175350.00\n",
            "1438  2898  199823.56\n",
            "1439  2899  204542.38\n",
            "1440  2900  164666.40\n",
            "1441  2901  231556.00\n",
            "1442  2902  238379.38\n",
            "1443  2903  267712.23\n",
            "1444  2904  325884.86\n",
            "1445  2905  122808.89\n",
            "1446  2906  247177.81\n",
            "1447  2907  125604.21\n",
            "1448  2908  129813.41\n",
            "1449  2909  223650.35\n",
            "1450  2910  137215.48\n",
            "1451  2911  129436.10\n",
            "1452  2912  150409.98\n",
            "1453  2913  151735.98\n",
            "1454  2914  110605.25\n",
            "1455  2915  107320.25\n",
            "1456  2916  130753.96\n",
            "1457  2917  173672.95\n",
            "1458  2918  165927.09\n",
            "1459  2919  207923.02\n",
            "\n",
            "[1459 rows x 2 columns]\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n",
            "explained_variance_score:  [0.699746186438703, 0.7358623953172436, 0.7415402264783313, 0.4703407471588109, 0.7630371460730315, 0.710918588051862, 0.7468265245946281, 0.7218466030081598, 0.7556415814317464, 0.7571300769333197]\n",
            "mean_squared_error:  [1395869754.7866707, 1745906426.8421085, 1475585671.4217498, 2503814815.1528296, 1553083254.1933138, 1611313957.199702, 1426974845.3020964, 1864125181.2300005, 1637175978.5443604, 1316769875.943862]\n",
            "mean_squared_log_error:  [0.04118167593689827, 0.044402384877385404, 0.04339582023403469, 0.054570367069246464, 0.029869097085494258, 0.04034637833880177, 0.04273491112148618, 0.044381770710324696, 0.040069754272510784, 0.03893419506892719]\n",
            "r2_score:  [0.6994693357167955, 0.7352384880147078, 0.7393742513772443, 0.46112872608070055, 0.7620454864581825, 0.709814496295079, 0.7457276495090894, 0.721646258957904, 0.7536542282640881, 0.7568606280423119]\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n",
            "explained_variance_score:  0.7102890075485836\n",
            "mean_squared_error:  1653061976.0616693\n",
            "mean_squared_log_error:  0.04198863547151097\n",
            "r2_score:  0.7084959548716103\n",
            "\n",
            " :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dict_keys(['fit_time', 'score_time', 'test_score', 'train_score'])\n",
            "Test Score:  [0.6109451  0.7942359  0.78963717 0.7210606  0.76398377 0.79700296\n",
            " 0.70280956 0.78195849 0.65103249 0.75181225]\n",
            "Test Score Average:  0.7364478298766384\n",
            "\n",
            "Train Score:  [0.9605702  0.95764737 0.95894392 0.95800064 0.95954764 0.95971809\n",
            " 0.96249705 0.96089275 0.96174878 0.96143476]\n",
            "Train Score Average:  0.9601001174664068\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dict_keys(['fit_time', 'score_time', 'test_explained_variance', 'train_explained_variance'])\n",
            "Test Variance:  [0.61914702 0.79626831 0.78972637 0.72148477 0.76551237 0.80058503\n",
            " 0.70589239 0.78198946 0.65103261 0.75629985]\n",
            "Test Variance Average:  0.7387938199282431\n",
            "\n",
            "Train Variance:  [0.96057557 0.95764743 0.95894502 0.95800261 0.95954769 0.95971886\n",
            " 0.96249867 0.96089535 0.96175571 0.96143788]\n",
            "Train Variance Average:  0.9601024782485718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sljNf5sYXdhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "reg = RandomForestRegressor(max_depth=50, random_state=1, n_estimators=50, max_features='auto')\n",
        "\n",
        "#reg.fit(x_maindata, y_maintarget)\n",
        "\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "predicted_value = reg.predict(x_test)\n",
        "new_predicted_value = reg.predict(x_maindata)\n",
        "print(predicted_value[0])\n",
        "print(predicted_value[0] - y_test[0])\n",
        "#print(reg.score(x_test, y_test))\n",
        "\n",
        "print(\"\\n\\n::::::::::::::::::::::::::::::\")\n",
        "scores = cross_val_score(reg, x_maindata, y_maintarget, cv=10)\n",
        "print(scores)\n",
        "print(scores.mean())\n",
        "#print(scores.keys())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(scores['test_score'])\n",
        "print(scores['test_score'].mean())\n",
        "print(scores['train_score'])\n",
        "print(scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n::::::::::::::::::::::::::::::\")\n",
        "\n",
        "from sklearn.metrics import explained_variance_score\n",
        "print(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "print(mean_squared_log_error(y_test, predicted_value))\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(y_test, predicted_value))\n",
        "\n",
        "#print(predicted_value)\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zQ_JZJ5aIHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "  reg = AdaBoostRegressor(loss='exponential', random_state=7, n_estimators = 100, learning_rate = 1.8)\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = AdaBoostRegressor(loss='exponential', random_state=7, n_estimators = 100, learning_rate = 1.8)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukbme7Ybc2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "reg = AdaBoostRegressor(loss='exponential', random_state=7, n_estimators = 100, learning_rate = 1.8)\n",
        "\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "predicted_value = reg.predict(x_test)\n",
        "print(predicted_value[0])\n",
        "print(predicted_value[0] - y_test[0])\n",
        "print(reg.score(x_test, y_test))\n",
        "\n",
        "\n",
        "print(\"\\n\\n::::::::::::::::::::::::::::::\")\n",
        "scores = cross_val_score(reg, x_maindata, y_maintarget, cv=10)\n",
        "print(scores)\n",
        "print(scores.mean())\n",
        "#print(scores.keys())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(scores['test_score'])\n",
        "print(scores['test_score'].mean())\n",
        "print(scores['train_score'])\n",
        "print(scores['train_score'].mean())\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEyaerE12OxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "  reg = GradientBoostingRegressor(loss='huber', random_state=7, n_estimators = 150, learning_rate = 0.5, subsample = 1)\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = GradientBoostingRegressor(loss='huber', random_state=7, n_estimators = 150, learning_rate = 0.5, subsample = 1)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zSgxz8kWjd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "reg = GradientBoostingRegressor(loss='huber', random_state=7, n_estimators = 150, learning_rate = 0.5, subsample = 1)\n",
        "\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "predicted_value = reg.predict(x_test)\n",
        "print(predicted_value[0])\n",
        "print(predicted_value[0] - y_test[0])\n",
        "print(reg.score(x_test, y_test))\n",
        "\n",
        "\n",
        "print(\"\\n\\n::::::::::::::::::::::::::::::\")\n",
        "scores = cross_val_score(reg, x_maindata, y_maintarget, cv=10)\n",
        "print(scores)\n",
        "print(scores.mean())\n",
        "#print(scores.keys())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(scores['test_score'])\n",
        "print(scores['test_score'].mean())\n",
        "print(scores['train_score'])\n",
        "print(scores['train_score'].mean())\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DwTBhmx3IFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "  reg = GradientBoostingRegressor(criterion='mse', random_state=7)\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = GradientBoostingRegressor(criterion='mse', random_state=7)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkWA547crzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "reg = GradientBoostingRegressor(criterion='mse', random_state=7)\n",
        "\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "predicted_value = reg.predict(x_test)\n",
        "\n",
        "print(predicted_value[0])\n",
        "print(predicted_value[0] - y_test[0])\n",
        "print(reg.score(x_test, y_test))\n",
        "\n",
        "print(\"\\n\\n::::::::::::::::::::::::::::::\")\n",
        "scores = cross_val_score(reg, x_maindata, y_maintarget, cv=10)\n",
        "print(scores)\n",
        "print(scores.mean())\n",
        "#print(scores.keys())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(scores['test_score'])\n",
        "print(scores['test_score'].mean())\n",
        "print(scores['train_score'])\n",
        "print(scores['train_score'].mean())\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDQPX3zXdo-W",
        "colab_type": "code",
        "outputId": "4643674b-fa3c-468b-9d80-bbaad822e7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "reg = LogisticRegression(penalty='l2', C=10, tol=0.0001, solver='newton-cg')\n",
        "\n",
        "reg.fit(x_train, y_train)\n",
        "\n",
        "predicted_value = reg.predict(x_test)\n",
        "print(predicted_value[0])\n",
        "print(predicted_value[0] - y_test[0])\n",
        "print(reg.score(x_test, y_test))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.linear_model import LogisticRegression\\n\\nreg = LogisticRegression(penalty='l2', C=10, tol=0.0001, solver='newton-cg')\\n\\nreg.fit(x_train, y_train)\\n\\npredicted_value = reg.predict(x_test)\\nprint(predicted_value[0])\\nprint(predicted_value[0] - y_test[0])\\nprint(reg.score(x_test, y_test))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o87S4gDrVBYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from statistics import mean\n",
        "folds = 10\n",
        "\n",
        "\n",
        "explained_variance_score_array = []\n",
        "mean_squared_error_array = []\n",
        "mean_squared_log_error_array = []\n",
        "r2_score_array = []\n",
        "\n",
        "for i in range(0,folds):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "  reg = XGBRegressor(n_estimators=50, booster='gbtree', learning_rate=0.1, max_delta_step=5)\n",
        "  \n",
        "  reg.fit(x_train, y_train)\n",
        "\n",
        "  predicted_value = reg.predict(x_test)\n",
        "  #print(predicted_value[0])\n",
        "  #print(predicted_value[0] - y_test[0])\n",
        "\n",
        "  from sklearn.metrics import explained_variance_score\n",
        "  explained_variance_score_array.append(explained_variance_score(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  mean_squared_error_array.append(mean_squared_error(y_test, predicted_value))\n",
        "\n",
        "  from sklearn.metrics import mean_squared_log_error\n",
        "  mean_squared_log_error_array.append(mean_squared_log_error(y_test, predicted_value))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  r2_score_array.append(r2_score(y_test, predicted_value))\n",
        "  \n",
        "  \n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",explained_variance_score_array)\n",
        "print(\"mean_squared_error: \",mean_squared_error_array)\n",
        "print(\"mean_squared_log_error: \",mean_squared_log_error_array)\n",
        "print(\"r2_score: \",r2_score_array)\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "print(\"explained_variance_score: \",mean(explained_variance_score_array))\n",
        "print(\"mean_squared_error: \",mean(mean_squared_error_array))\n",
        "print(\"mean_squared_log_error: \",mean(mean_squared_log_error_array))\n",
        "print(\"r2_score: \",mean(r2_score_array))\n",
        "\n",
        "print(\"\\n :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_maindata, y_maintarget, test_size=.25)\n",
        "reg = XGBRegressor(n_estimators=100, booster='gblinear', learning_rate=1.5, max_delta_step=5, base_score=0.25)\n",
        "\n",
        "#scoring_parameter = ['explained_variance','test_score','train_score']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Score: \",scores['test_score'])\n",
        "print(\"Test Score Average: \", scores['test_score'].mean())\n",
        "print()\n",
        "print(\"Train Score: \",scores['train_score'])\n",
        "print(\"Train Score Average: \",scores['train_score'].mean())\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\\n\")\n",
        "scoring_parameter = ['explained_variance']\n",
        "scores = cross_validate(reg, x_maindata, y_maintarget, cv=10, return_train_score=True, scoring=scoring_parameter)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\\n\")\n",
        "print(scores.keys())\n",
        "print(\"Test Variance: \",scores['test_explained_variance'])\n",
        "print(\"Test Variance Average: \",scores['test_explained_variance'].mean())\n",
        "print()\n",
        "print(\"Train Variance: \",scores['train_explained_variance'])\n",
        "print(\"Train Variance Average: \",scores['train_explained_variance'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvY12v-d0POe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}